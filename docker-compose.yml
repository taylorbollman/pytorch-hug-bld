version: '3'
services:
  my_hugtranformer_service:
    image: gpu-and-tranformers-img
    build: 
      context: .
      dockerfile: Dockerfile
    command: tail -f /dev/null
    volumes:
      - ./pytorch-huggingface-tutorial:/code  # Bind mount for development
    environment:
      - "ENV_VAR=value"
    ports:
      - "8000:8000"  # Map port 8000 inside the container to port 8000 on the host
    deploy:
      resources:
        reservations:
          memory: 4G
    runtime: nvidia  # Enable NVIDIA runtime for GPU support
